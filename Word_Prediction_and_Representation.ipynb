{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pm6no8oIn6X3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data taken from https://www.kaggle.com/datasets/notlucasp/financial-news-headlines?select=guardian_headlines.csv"
      ],
      "metadata": {
        "id": "DKJp8EfLtxTa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "sentences = []\n",
        "with open('./guardian_headlines.csv', 'r') as f:\n",
        "    csvreader = csv.reader(f)\n",
        "    for row in csvreader:\n",
        "      words = row[1].split()\n",
        "      sentence = [word.lower() for word in words]\n",
        "      sentences.append(sentence)\n",
        "\n",
        "sentences.pop(0) # removing heading of list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl6ijq_9oOd6",
        "outputId": "5c6dd59c-7232-4eab-8d41-8e0afd0430f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['headlines']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of sentences:\", len(sentences))\n",
        "vocab = set([word for sentence in sentences for word in sentence])\n",
        "print(\"Size of vocabulary:\", len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t66oJXHlykd5",
        "outputId": "4e1e7f8f-cb00-4663-c807-9d898b67fe07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 17800\n",
            "Size of vocabulary: 23491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_lengths = [len(sentence) for sentence in sentences]\n",
        "print(\"Min length\", np.min(sentence_lengths))\n",
        "print(\"Average length\", np.mean(sentence_lengths))\n",
        "print(\"Max length\", np.max(sentence_lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGshAuEA0LYg",
        "outputId": "97e6af21-8bdf-4c2a-86fb-a8b401957ae0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min length 3\n",
            "Average length 11.021348314606742\n",
            "Max length 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "shuffle(sentences)\n",
        "\n",
        "train_data = sentences[:int(0.8 * len(sentences))]\n",
        "val_data = sentences[int(0.8 * len(sentences)):int(0.9 * len(sentences))]\n",
        "test_data = sentences[int(0.9 * len(sentences)):]\n",
        "\n",
        "print(len(train_data), len(val_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXCpEqjP0sFZ",
        "outputId": "9c14478d-c5a3-4626-fd9f-504b8553e8c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14240 1780 1780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_count = Counter([w for sentence in sentences for w in sentence])\n",
        "print(word_count.most_common(1))"
      ],
      "metadata": {
        "id": "Q22x3Lkg1VRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a9ef68-4f9e-4e58-8ffc-88d601081905"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('to', 6220)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create vocab dictionary\n",
        "vocab = set([w for sentence in sentences for w in sentence])\n",
        "word_index = {w:i for i, w in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "o7-hI7ax5U20"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert words to indices\n",
        "\n",
        "def words_to_indices(sentences):\n",
        "\n",
        "  return [[word_index[word] for word in sentence] for sentence in sentences]\n",
        "\n",
        "def generate_4grams(indices):\n",
        "\n",
        "  four_grams = []\n",
        "  for sentence in indices:\n",
        "    for i in range(len(sentence) - 4):\n",
        "      four_grams.append(sentence[i:i+4])\n",
        "\n",
        "  return four_grams\n",
        "\n",
        "def compile_data(sentences):\n",
        "  indices = words_to_indices(sentences)\n",
        "  four_grams = generate_4grams(indices)\n",
        "  return np.array(four_grams)\n",
        "\n",
        "grams = compile_data(train_data)\n",
        "print(grams.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5QqWto45xaI",
        "outputId": "2260220e-13ef-44ea-84c3-90c9997b021f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99950, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding the input\n",
        "\n",
        "def onehot_encoder(four_grams, vocab_size):\n",
        "  I = np.eye(vocab_size)\n",
        "  return I[four_grams]\n",
        "\n",
        "print(onehot_encoder(grams, len(vocab)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34O4s9319Vqq",
        "outputId": "5f0c2c9a-7bfc-4142-d8f4-011d4d5c6c50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99950, 4, 23491)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data, range_min, range_max, onehot=True):\n",
        "\n",
        "  X = data[range_min:range_max, :3]\n",
        "  t = data[range_min:range_max, 3]\n",
        "\n",
        "  X = onehot_encoder(X, len(vocab))\n",
        "\n",
        "  X = X.reshape(-1, 3 * len(vocab))\n",
        "\n",
        "  if onehot:\n",
        "    t = onehot_encoder(t, len(vocab))\n",
        "    t = t.reshape(-1, len(vocab))\n",
        "\n",
        "  return X, t\n",
        "\n",
        "# test the data out\n",
        "\n",
        "grams = compile_data(train_data)\n",
        "X, t = get_batch(grams, 0, 10, onehot=False)\n",
        "print(X.shape, t.shape)\n",
        "\n",
        "# check if indices are at the right position\n",
        "for i in range(3):\n",
        "  index_pos = grams[0][i]\n",
        "  print(X[0][index_pos + ((len(vocab) * i) - 1)]) # should be 0\n",
        "  print(X[0][index_pos + (len(vocab) * i)]) # should 1\n",
        "  print(X[0][index_pos + ((len(vocab) * i) + 1)]) # should be 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q10KQeKZ-4zy",
        "outputId": "c123ab00-fc35-479a-94bf-5e43fb3c1eae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 70473) (10,)\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    }
  ]
}