{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "pm6no8oIn6X3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget !wget https://www.cs.toronto.edu/~lczhang/413/raw_sentences.txt"
      ],
      "metadata": {
        "id": "DKJp8EfLtxTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc229ec-7991-4629-81d1-38e08ad6adfb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-10 04:14:10--  http://!wget/\n",
            "Resolving !wget (!wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘!wget’\n",
            "--2024-02-10 04:14:10--  https://www.cs.toronto.edu/~lczhang/413/raw_sentences.txt\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2955731 (2.8M) [text/plain]\n",
            "Saving to: ‘raw_sentences.txt.1’\n",
            "\n",
            "raw_sentences.txt.1 100%[===================>]   2.82M  1.91MB/s    in 1.5s    \n",
            "\n",
            "2024-02-10 04:14:13 (1.91 MB/s) - ‘raw_sentences.txt.1’ saved [2955731/2955731]\n",
            "\n",
            "FINISHED --2024-02-10 04:14:13--\n",
            "Total wall clock time: 2.9s\n",
            "Downloaded: 1 files, 2.8M in 1.5s (1.91 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for line in open('./raw_sentences.txt', 'r'):\n",
        "\n",
        "      words = line.split()\n",
        "      sentence = [word.lower() for word in words]\n",
        "      sentences.append(sentence)"
      ],
      "metadata": {
        "id": "zl6ijq_9oOd6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of sentences:\", len(sentences))\n",
        "vocab = set([word for sentence in sentences for word in sentence])\n",
        "print(\"Size of vocabulary:\", len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t66oJXHlykd5",
        "outputId": "435bb17c-4597-40fc-9736-f5663784c531"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 97162\n",
            "Size of vocabulary: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_lengths = [len(sentence) for sentence in sentences]\n",
        "print(\"Min length\", np.min(sentence_lengths))\n",
        "print(\"Average length\", np.mean(sentence_lengths))\n",
        "print(\"Max length\", np.max(sentence_lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGshAuEA0LYg",
        "outputId": "15dc4ae7-0ab3-4daf-c638-ce8668fdbc5a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min length 4\n",
            "Average length 7.792881990901793\n",
            "Max length 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "shuffle(sentences)\n",
        "\n",
        "train_data = sentences[:int(0.8 * len(sentences))]\n",
        "val_data = sentences[int(0.8 * len(sentences)):int(0.9 * len(sentences))]\n",
        "test_data = sentences[int(0.9 * len(sentences)):]\n",
        "\n",
        "print(len(train_data), len(val_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXCpEqjP0sFZ",
        "outputId": "54d8b055-3f4e-44b5-b754-ead2c1e0d393"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77729 9716 9717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_count = Counter([w for sentence in sentences for w in sentence])\n",
        "print(word_count.most_common(1))"
      ],
      "metadata": {
        "id": "Q22x3Lkg1VRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce54cc9-fa67-4b89-be18-9a320683f0dd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('.', 80974)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create vocab dictionary\n",
        "vocab = set([w for sentence in sentences for w in sentence])\n",
        "word_index = {w:i for i, w in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "o7-hI7ax5U20"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert words to indices\n",
        "\n",
        "def words_to_indices(sentences):\n",
        "\n",
        "  return [[word_index[word] for word in sentence] for sentence in sentences]\n",
        "\n",
        "def generate_4grams(indices):\n",
        "\n",
        "  four_grams = []\n",
        "  for sentence in indices:\n",
        "    for i in range(len(sentence) - 4):\n",
        "      four_grams.append(sentence[i:i+4])\n",
        "\n",
        "  return four_grams\n",
        "\n",
        "def compile_data(sentences):\n",
        "  indices = words_to_indices(sentences)\n",
        "  four_grams = generate_4grams(indices)\n",
        "  return np.array(four_grams)\n",
        "\n",
        "grams = compile_data(train_data)\n",
        "print(grams.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5QqWto45xaI",
        "outputId": "4c194507-244b-4aa7-b2e7-5206d14a0295"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(294501, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding the input\n",
        "\n",
        "def onehot_encoder(four_grams, vocab_size):\n",
        "  I = np.eye(vocab_size)\n",
        "  return I[four_grams]\n",
        "\n",
        "print(onehot_encoder(grams, len(vocab)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34O4s9319Vqq",
        "outputId": "47a1956a-3cfc-4c8d-d025-70437e2b978c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(294501, 4, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data, range_min, range_max, onehot=True):\n",
        "\n",
        "  X = data[range_min:range_max, :3]\n",
        "  t = data[range_min:range_max, 3]\n",
        "\n",
        "  X = onehot_encoder(X, len(vocab))\n",
        "\n",
        "  X = X.reshape(-1, 3 * len(vocab))\n",
        "\n",
        "  if onehot:\n",
        "    t = onehot_encoder(t, len(vocab))\n",
        "    t = t.reshape(-1, len(vocab))\n",
        "\n",
        "  return X, t\n",
        "\n",
        "# test the data out\n",
        "\n",
        "grams = compile_data(train_data)\n",
        "X, t = get_batch(grams, 0, 10, onehot=False)\n",
        "print(X.shape, t.shape)\n",
        "\n",
        "# check if indices are at the right position\n",
        "for i in range(3):\n",
        "  index_pos = grams[0][i]\n",
        "  print(X[0][index_pos + ((len(vocab) * i) - 1)]) # should be 0\n",
        "  print(X[0][index_pos + (len(vocab) * i)]) # should 1\n",
        "  print(X[0][index_pos + ((len(vocab) * i) + 1)]) # should be 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q10KQeKZ-4zy",
        "outputId": "ff4ef053-7660-4f92-ea3c-1c4afa462b64"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 750) (10,)\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, data, batch=100, max_N=10000):\n",
        "  num_correct = 0\n",
        "  num_pred = 0\n",
        "\n",
        "  for i in range(0, data.shape[0], batch):\n",
        "    X, t = get_batch(data, i, i+1, onehot=False)\n",
        "    z = model.forward(X)\n",
        "    pred = np.argmax(z, axis=1)\n",
        "\n",
        "    num_correct += np.sum(pred == t)\n",
        "    num_pred += t.shape[0]\n",
        "\n",
        "    if num_pred >= max_N:\n",
        "      break\n",
        "\n",
        "  return num_correct / num_pred"
      ],
      "metadata": {
        "id": "gMRuLTJNPKc2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "\n",
        "  x = x.T\n",
        "  exps = np.exp(x - x.max(axis=0))\n",
        "  probs = exps / np.sum(exps, axis=0)\n",
        "  return probs.T"
      ],
      "metadata": {
        "id": "FlaUR8TnJ3az"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NNModel:\n",
        "\n",
        "  def __init__(self, vocab_size, emb_size, num_hidden):\n",
        "\n",
        "    self.vocab_size = vocab_size\n",
        "    self.emb_size = emb_size\n",
        "    self.num_hidden = num_hidden\n",
        "\n",
        "    self.Ww = np.zeros([vocab_size, emb_size])\n",
        "    # self.bw = np.zeros([emb_size])\n",
        "\n",
        "    self.W1 = np.zeros([emb_size * 3, num_hidden])\n",
        "    self.b1 = np.zeros([num_hidden])\n",
        "\n",
        "    self.W2 = np.zeros([num_hidden, vocab_size])\n",
        "    self.b2 = np.zeros([vocab_size])\n",
        "\n",
        "    self.initialize_weights()\n",
        "\n",
        "    self.cleanup()\n",
        "\n",
        "  def initialize_weights(self):\n",
        "\n",
        "    self.Ww = np.random.normal(0, 2/(self.vocab_size), self.Ww.shape)\n",
        "\n",
        "    self.W1 = np.random.normal(0, 2/(3*self.emb_size), self.W1.shape)\n",
        "    self.b1 = np.random.normal(0, 2/(3*self.emb_size), self.b1.shape)\n",
        "\n",
        "    self.W2 = np.random.normal(0, 2/(self.num_hidden), self.W2.shape)\n",
        "    self.b2 = np.random.normal(0, 2/(self.num_hidden), self.b2.shape)\n",
        "\n",
        "  def cleanup(self):\n",
        "\n",
        "    self.N = None\n",
        "    self.xa = None\n",
        "    self.xb = None\n",
        "    self.xc = None\n",
        "    self.va = None\n",
        "    self.vb = None\n",
        "    self.vc = None\n",
        "    self.v = None\n",
        "    self.m = None\n",
        "    self.h = None\n",
        "    self.z = None\n",
        "    self.y = None\n",
        "\n",
        "    self.z_bar = None\n",
        "    self.W2_bar = None\n",
        "    self.b2_bar = None\n",
        "    self.h_bar = None\n",
        "    self.m_bar = None\n",
        "    self.W1_bar = None\n",
        "    self.b1_bar = None\n",
        "    self.v_bar = None\n",
        "    self.va_bar = None\n",
        "    self.vb_bar = None\n",
        "    self.vc_bar = None\n",
        "    self.Ww_bar = None\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "    return do_forward_pass(self, X)\n",
        "\n",
        "  def backward(self, t):\n",
        "\n",
        "    return do_backward_pass(self, t)\n",
        "\n",
        "  def loss(self, t):\n",
        "\n",
        "    # Cross Entropy Loss\n",
        "    pred = np.sum(-t * np.log(self.y)) / t.shape[0]\n",
        "    return pred\n",
        "\n",
        "  def update(self, alpha):\n",
        "\n",
        "    self.Ww = self.Ww - alpha * self.Ww_bar\n",
        "    self.W1 = self.W1 - alpha * self.W1_bar\n",
        "    self.b1 = self.b1 - alpha * self.b1_bar\n",
        "    self.W2 = self.W2 - alpha * self.W2_bar\n",
        "    self.b2 = self.b2 - alpha * self.b2_bar"
      ],
      "metadata": {
        "id": "VyXp1PwDQWAg"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_forward_pass(model, X):\n",
        "\n",
        "  model.N = X.shape[0]\n",
        "  model.X = X\n",
        "\n",
        "  model.xa = X[:, 0:model.vocab_size]\n",
        "  model.xb = X[:, model.vocab_size:2*model.vocab_size]\n",
        "  model.xc = X[:, 2*model.vocab_size:]\n",
        "\n",
        "  # compute embeddings\n",
        "  model.va = np.matmul(model.xa, model.Ww)\n",
        "  model.vb = np.matmul(model.xb, model.Ww)\n",
        "  model.vc = np.matmul(model.xc, model.Ww)\n",
        "  model.v = np.concatenate([model.va, model.vb, model.vc], axis=1)\n",
        "\n",
        "  # compute pre-hidden layer input\n",
        "  model.m = np.matmul(model.v, model.W1) + model.b1\n",
        "\n",
        "  # compute post hidden layer - ReLU activation\n",
        "  model.h = np.maximum(0, model.m)\n",
        "\n",
        "  # compute logits\n",
        "  model.z = np.matmul(model.h, model.W2) + model.b2\n",
        "\n",
        "  # compute class probabilities\n",
        "  model.y = softmax(model.z)\n",
        "\n",
        "  return model.z"
      ],
      "metadata": {
        "id": "Il8QLyk7EdNa"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, t = get_batch(grams, 0, 10)\n",
        "model = NNModel(len(vocab), 150, 100)\n",
        "y = model.forward(x)\n",
        "\n",
        "print(model.va.shape, model.vb.shape, model.vc.shape)\n",
        "print(model.v.shape)\n",
        "print(model.z.shape)\n",
        "print(model.z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl9blSc2KnH6",
        "outputId": "b6035354-ae99-4805-f683-f2c3c92432f8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 150) (10, 150) (10, 150)\n",
            "(10, 450)\n",
            "(10, 250)\n",
            "(10, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy(model, grams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UubbLEljM7iQ",
        "outputId": "53fa50ff-98cb-4753-dd07-601a33a93a9e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0010183299389002036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IAUr5BLAOHEB"
      },
      "execution_count": 54,
      "outputs": []
    }
  ]
}